{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import keras as kr\n",
    "import keras.layers as kl\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path dataset\n",
    "train_path = \"./dataset/AI Dataset/train\"\n",
    "test_path = \"./dataset/AI Dataset/test\"\n",
    "valid_path = \"./dataset/AI Dataset/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "def get_dataset(file_path):\n",
    "    # load csv\n",
    "    dataset = pd.read_csv(os.path.join(file_path, \"_classes.csv\"))\n",
    "\n",
    "    # extract filename\n",
    "    classes = dataset.columns\n",
    "    file_names = dataset.iloc[:,0].values # dapetin file name dari kolom 0, .values ubah ke list\n",
    "    # [baris, kolom]\n",
    "    # mau dapetin labelnya sesuai dengan imagenya\n",
    "    label = [] # nyimpen labelnya\n",
    "    image = [] # nyimpen gambar\n",
    "    max_label = dataset.iloc[:,1:].values # [[1, 0, 0, 0, 0, 0, 0], [] ... ]\n",
    "    max_label = np.argmax(max_label, axis=1) # [0, 3, 1, 2]\n",
    "    for i, img_path in enumerate(file_names):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(file_path, img_path))\n",
    "            img = img/255.0 # normalize\n",
    "            if(max_label[i] != 6):\n",
    "                # append\n",
    "                label.append(max_label[i])\n",
    "                image.append(img)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    # ubah menjadi data buat tensorflow, menjadi tuple\n",
    "    tf_data = tf.data.Dataset.from_tensor_slices((image, label)).batch(16)   \n",
    "    return tf_data, classes[1:-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_classes = get_dataset(train_path)\n",
    "test_data, _ = get_dataset(test_path)\n",
    "valid_data, _ = get_dataset(valid_path)\n",
    "\n",
    "print(train_data, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_data))\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet model\n",
    "def alexnet(num_of_classes):\n",
    "\n",
    "    # convolution\n",
    "    # filter: output kernel\n",
    "    # kernel_size: kernel yang dipake\n",
    "    # stride: jumlah stride(skip)\n",
    "\n",
    "    # maxpool ga ada activation, cuman downsampling\n",
    "    # di keras, padding itu ga usah dipeduliin, bilang aja same\n",
    "\n",
    "\n",
    "    model = kr.Sequential([\n",
    "        # width * height * channel\n",
    "        kl.Input(shape=(224, 224, 3)),\n",
    "        kl.Conv2D(filters=96, kernel_size=11, strides=4, activation=\"relu\"),\n",
    "        kl.MaxPool2D(pool_size=3, strides=2),\n",
    "        kl.Conv2D(filters=256, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
    "        kl.MaxPool2D(pool_size=3, strides=2),\n",
    "        kl.Conv2D(filters=384, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "        kl.Conv2D(filters=384, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "        kl.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "        kl.MaxPool2D(pool_size=3, strides=2),\n",
    "\n",
    "        # ubah jadi 1d, fully connected layer\n",
    "        kl.Flatten(),\n",
    "        kl.Dense(4096, activation=\"relu\"),\n",
    "        kl.Dropout(0.5),\n",
    "        kl.Dense(4096, activation=\"relu\"),\n",
    "        kl.Dropout(0.5),\n",
    "        # pake softmax agar memberikan probability score\n",
    "        kl.Dense(num_of_classes, activation=\"softmax\") # output\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet(len(train_classes))\n",
    "# model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, epochs=15, validation_data=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report\n",
    "# test_img = []\n",
    "# test_label = []\n",
    "\n",
    "# for img_batch, label_batch in test_data:\n",
    "#     # split\n",
    "#     test_img.append(img_batch)\n",
    "#     test_label.extend(label_batch)\n",
    "\n",
    "# predicted = model.predict(test_img)\n",
    "\n",
    "test_img = test_data.map(lambda x, y:x)\n",
    "test_label = test_data.map(lambda x, y:y)\n",
    "predicted = model.predict(test_img)\n",
    "\n",
    "labels = []\n",
    "for label in test_label:\n",
    "    labels.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels, np.argmax(predicted, axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
